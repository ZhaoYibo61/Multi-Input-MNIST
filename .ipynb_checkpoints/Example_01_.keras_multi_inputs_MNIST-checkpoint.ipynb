{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example) Visualize Multi-input MNIST Activation Map (1/2)**\n",
    "### *Initialize and training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Initialize GPU memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# GPU constraints\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True \n",
    "sess = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Load MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original MNIST dataset shapes\n",
      "(60000, 28, 28, 1) (60000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = x_test.astype(np.float32) / 255\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "print(\"Original MNIST dataset shapes\")\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Preprocess for multi-input classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def multi_input_mnist(X, Y):\n",
    "    x1_indices = np.arange(len(X))\n",
    "    np.random.shuffle(x1_indices)\n",
    "    X1 = deepcopy(X[x1_indices])\n",
    "    Y1 = deepcopy(Y[x1_indices])\n",
    "\n",
    "    x2_indices = np.arange(len(X))\n",
    "    np.random.shuffle(x2_indices)\n",
    "    X2 = deepcopy(X[x2_indices])\n",
    "    Y2 = deepcopy(Y[x2_indices])\n",
    "\n",
    "    print(Y)\n",
    "\n",
    "    Y = []\n",
    "    for y1, y2 in zip(Y1, Y2):\n",
    "        if y1 == y2:\n",
    "            #print(\"y1 : {} / y2 : {}\".format(y1, y2))\n",
    "            Y.append([True])\n",
    "        else:\n",
    "            Y.append([False])\n",
    "\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    print(\"Multi-input MNIST dataset shapes\")\n",
    "    print(\"x1 : {}\".format(X1.shape))\n",
    "    print(\"x2 : {}\".format(X2.shape))\n",
    "    print(\"y  : {}\".format(Y.shape))\n",
    "    print(\"number of positive : {}\".format(np.sum(Y)))\n",
    "    return X1, X2, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "Multi-input MNIST dataset shapes\n",
      "x1 : (60000, 28, 28, 1)\n",
      "x2 : (60000, 28, 28, 1)\n",
      "y  : (60000, 1)\n",
      "number of positive : 5955\n"
     ]
    }
   ],
   "source": [
    "x1_train, x2_train, y_train = multi_input_mnist(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "Multi-input MNIST dataset shapes\n",
      "x1 : (10000, 28, 28, 1)\n",
      "x2 : (10000, 28, 28, 1)\n",
      "y  : (10000, 1)\n",
      "number of positive : 972\n"
     ]
    }
   ],
   "source": [
    "x1_test, x2_test, y_test = multi_input_mnist(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]] 972 10000 0.9028\n"
     ]
    }
   ],
   "source": [
    "print(y_test, np.sum(y_test), len(y_test), 1 - np.sum(y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Initialize classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Concatenate, Conv2D, Activation, Flatten\n",
    "\n",
    "def base_model():\n",
    "    input_x1 = Input(shape=(28,28,1))\n",
    "    x1 = Conv2D(filters=64, kernel_size=(8,8), padding=\"same\", strides=1)(input_x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1_out = x1\n",
    "    x1 = Conv2D(filters=128, kernel_size=(4,4), padding=\"same\", strides=2)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv2D(filters=128, kernel_size=(2,2), padding=\"same\", strides=2)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    \n",
    "    input_x2 = Input(shape=(28,28,1))\n",
    "    x2 = Conv2D(filters=64, kernel_size=(8,8), padding=\"same\", strides=1)(input_x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2_out = x2\n",
    "    x2 = Conv2D(filters=128, kernel_size=(4,4), padding=\"same\", strides=2)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Conv2D(filters=128, kernel_size=(2,2), padding=\"same\", strides=2)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    \n",
    "    x1 = Flatten()(x1)\n",
    "    x2 = Flatten()(x2)\n",
    "    \n",
    "    x = Concatenate()([x1, x2])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    y = x\n",
    "    \n",
    "    model_x1 = Model(input_x1, x1_out)\n",
    "    model_x2 = Model(input_x2, x2_out)\n",
    "    model = Model([input_x1, input_x2], y)\n",
    "    return model, model_x1, model_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_x1, model_x2 = base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 64)   4160        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 64)   4160        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28, 28, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 128)  131200      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 128)  131200      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 14, 14, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 128)    65664       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 128)    65664       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 7, 7, 128)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 6272)         0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12544)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          1605760     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            33          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,011,969\n",
      "Trainable params: 2,011,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "=================================================================\n",
      "Total params: 4,160\n",
      "Trainable params: 4,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_x1.summary() # first layer output model of input x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 64)        0         \n",
      "=================================================================\n",
      "Total params: 4,160\n",
      "Trainable params: 4,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_x2.summary() # first layer output model of input x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Compile and train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.3429 - acc: 0.8878 - val_loss: 0.3189 - val_acc: 0.9028\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.3240 - acc: 0.9007 - val_loss: 0.3186 - val_acc: 0.9028\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3233 - acc: 0.9007 - val_loss: 0.3187 - val_acc: 0.9028\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3234 - acc: 0.9008 - val_loss: 0.3185 - val_acc: 0.9028\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3213 - acc: 0.9008 - val_loss: 0.3173 - val_acc: 0.9028\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3111 - acc: 0.9007 - val_loss: 0.2760 - val_acc: 0.9028\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2231 - acc: 0.9135 - val_loss: 0.1754 - val_acc: 0.9270\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1240 - acc: 0.9510 - val_loss: 0.0933 - val_acc: 0.9656\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0804 - acc: 0.9698 - val_loss: 0.0717 - val_acc: 0.9728\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0554 - acc: 0.9797 - val_loss: 0.0660 - val_acc: 0.9773\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0408 - acc: 0.9857 - val_loss: 0.0570 - val_acc: 0.9795\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0309 - acc: 0.9888 - val_loss: 0.0553 - val_acc: 0.9815\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0239 - acc: 0.9919 - val_loss: 0.0510 - val_acc: 0.9825\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0633 - val_acc: 0.9827\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.0588 - val_acc: 0.9848\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0647 - val_acc: 0.9832\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0698 - val_acc: 0.9827\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0695 - val_acc: 0.9851\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0692 - val_acc: 0.9843\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0873 - val_acc: 0.9821\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0757 - val_acc: 0.9849\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0788 - val_acc: 0.9841\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 7.7206e-04 - acc: 0.9999 - val_loss: 0.0840 - val_acc: 0.9854\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 3.9479e-04 - acc: 1.0000 - val_loss: 0.0766 - val_acc: 0.9851\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 1.3425e-04 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9849\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 7.4972e-05 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9858\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 5.2859e-05 - acc: 1.0000 - val_loss: 0.0821 - val_acc: 0.9859\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 4.3475e-05 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9856\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 3.7291e-05 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 0.9856\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 3.2732e-05 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef30702b70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[x1_train, x2_train], \n",
    "          y=y_train,\n",
    "          batch_size=1000,\n",
    "          epochs=30, \n",
    "          shuffle=True,\n",
    "          validation_data=([x1_test, x2_test], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Save trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/example01.h5')\n",
    "model_x1.save('models/example01-1.h5')\n",
    "model_x2.save('models/example01-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
